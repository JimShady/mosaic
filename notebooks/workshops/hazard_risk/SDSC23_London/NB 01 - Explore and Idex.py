# Databricks notebook source
# MAGIC %md
# MAGIC ## Install and enable mosaic. 
# MAGIC We will leverage both vector and raster data so we will also enable GDAL support in mosaic.

# COMMAND ----------

# MAGIC %pip install databricks-mosaic --quiet

# COMMAND ----------

import mosaic as mos
import pyspark.sql.functions as F
mos.enable_mosaic(spark, dbutils)
mos.enable_gdal(spark)

# COMMAND ----------

# MAGIC %md
# MAGIC Because geospatial data is very particular:
# MAGIC * Each row of data isnt always equal to other data rows
# MAGIC * Individual rows require a lot of compute
# MAGIC * Small partitions are desirable for geospatial data </br>
# MAGIC
# MAGIC We should turn off the adaptive query execution otpimization in spark.

# COMMAND ----------

spark.conf.set("spark.databricks.optimizer.adaptive.enabled", "false")

# COMMAND ----------

# MAGIC %sql
# MAGIC CREATE DATABASE IF NOT EXISTS flood_risk;
# MAGIC USE flood_risk;

# COMMAND ----------

# MAGIC %md
# MAGIC ### Load road data
# MAGIC We have 60+ shape files that are provided zipped.

# COMMAND ----------

# MAGIC %fs ls dbfs:/geospatial/hazard_risk/road/shapefile/

# COMMAND ----------

# MAGIC %md
# MAGIC Mosaic brings native readers for spark for both .shp and .zip shapefiles. </br>
# MAGIC When loading .zip files we need to provide "vsizip" = "true" option. </br>
# MAGIC There is no need to manually unzip any files. </br>
# MAGIC For multi-layer files, you can specify the layer by "layerNumber" = N.

# COMMAND ----------

roads_df = mos.read()\
  .format("multi_read_ogr")\
  .option("vsizip", "true")\
  .load("dbfs:/geospatial/hazard_risk/road/shapefile/")\
  .repartition(200, F.rand()) # ensure data is reshuffled, this is important for geospatial data after reading

roads_df.display()

# COMMAND ----------

# MAGIC %md
# MAGIC It takes less than a minute to automatically with 1 command:
# MAGIC - List zip files
# MAGIC - Infer the schema
# MAGIC - Parse the files
# MAGIC - Return results
# MAGIC Note: Geometries are returned as WKB. You can use mos.st_astext() to convert these to WKT.

# COMMAND ----------

# MAGIC %md
# MAGIC We can use mosaic kepler magic to easily visualise a sample of the data in an interactive map

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC roads_df "geom_0" "geometry" 20000

# COMMAND ----------

# MAGIC %md
# MAGIC We will use Mosaic to index our roads dataset using grid_tessellateexplod method.
# MAGIC All different datasets will be indexed to h3 resolution 9.

# COMMAND ----------

roads_df\
  .withColumn("grid", mos.grid_tessellateexplode("geom_0", F.lit(7)))\
  .write\
  .mode("overwrite")\
  .saveAsTable("roads")

# COMMAND ----------

# MAGIC %md
# MAGIC Indexed data will store partial geometries next to each cell id. 
# MAGIC For illustration purpose we will visualise these partial geometries as well known text (these are stored as well known byte in grid.wkb column generated by tessellation). 

# COMMAND ----------

spark.read.table("roads").withColumn(
  "wkt", mos.st_astext(F.col("grid.wkb"))
).display()

# COMMAND ----------

df1 = spark.read.table("roads").withColumn(
  "wkt", mos.st_astext(F.col("grid.wkb"))
).select(
  F.col("wkt"),
  F.col("grid.index_id")
)

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC df1 "index_id" "h3" 5000

# COMMAND ----------

# MAGIC %md
# MAGIC ### Load Weather data

# COMMAND ----------

# MAGIC %md
# MAGIC Weather data is provided as NetCDF file set.
# MAGIC NetCDF is a raster format. When working with raster formats it is very important to interpret the metadata contained within the raster file. Mosaic comes with helper methods to extract raster metadata.

# COMMAND ----------

weather_metadata_df = (
  spark.read.format("binaryFile").option("pathGlobFilter", "*.nc").load("dbfs:/geospatial/hazard_risk/weather/")
    .drop("content")
      .withColumn("subdatasets", mos.rst_subdatasets("path"))
      .withColumn("num_bands", mos.rst_numbands("path"))
      .withColumn("metadata", mos.rst_metadata("path"))
      .withColumn("summary", mos.rst_summary("path"))
)

weather_metadata_df.display()

# COMMAND ----------

# MAGIC %md
# MAGIC Mosaic comes with "raster_to_grid" optimized reader that will allow us to automatically convert all our bands in the raster to grid cells and per cell measurements. In our case we are using H3, but other grids are supported as well. We will automatically ingest data at resolution 4, due to the size of raster pixels. We will then generate children at resolution 9 for each cell that will have the same measurement as the parent cell.

# COMMAND ----------

weather_df = mos.read()\
  .format("raster_to_grid")\
  .option("resolution", "4")\
  .option("readSubdataset", "true")\
  .option("subdatasetName", "precip")\
  .option("combiner", "mean")\
  .load("dbfs:/geospatial/hazard_risk/weather/")\
  .repartition(200, F.rand()) # ensure data is reshuffled, this is important for geospatial data after reading

weather_df.display()

# COMMAND ----------

weather_df_1 = weather_df.where("band_id == 1")
weather_df_123 = weather_df.where("band_id == 123")

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC weather_df_1 cell_id h3 30000000

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC weather_df_123 cell_id h3 30000000

# COMMAND ----------

weather_df\
  .withColumn("cell_id", F.expr("h3_tochildren(cell_id, 7)"))\
  .withColumn("cell_id", F.explode("cell_id"))\
  .write\
  .mode("overwrite")\
  .option("overwriteSchema", "true")\
  .saveAsTable("weather")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Load Bridges data

# COMMAND ----------

# MAGIC %md
# MAGIC In many cases geospatial data will come in zipped files. Mosaic supports automatic unzipping at read time. There is no need to manually unzip files.

# COMMAND ----------

# MAGIC %fs ls dbfs:/geospatial/hazard_risk/bridge/

# COMMAND ----------

bridge_df = mos.read()\
  .format("multi_read_ogr")\
  .option("vsizip", "true")\
  .option("chunkSize", "200")\
  .load("dbfs:/geospatial/hazard_risk/bridge/")\
  .repartition(200, F.rand())\
  .withColumn("SHAPE_SRID", F.col("SHAPE_SRID").cast("int"))\
  .withColumn("geom_0", mos.st_updatesrid("SHAPE", "SHAPE_SRID", F.lit(4326)))\
  .drop("SHAPE")

bridge_df.display()

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC bridge_df "geom_0" "geometry" 10000

# COMMAND ----------

bridge_df\
  .withColumn("cell_id", mos.grid_pointascellid("geom_0", F.lit(7)))\
  .write.mode("overwrite")\
  .saveAsTable("bridges")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Load Hydrography data

# COMMAND ----------

nhda_area = mos.read()\
  .format("multi_read_ogr")\
  .option("vsizip", "false")\
  .load("dbfs:/geospatial/hazard_risk/hydrography/data/Shape/NHDArea.shp")\
  .repartition(200, F.rand()) # ensure data is reshuffled, this is important for geospatial data after reading


nhda_area.display()

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC nhda_area "geom_0" "geometry"

# COMMAND ----------

nhda_area\
  .repartition(20, F.col("geom_0"))\
  .withColumn("cell_id", mos.grid_tessellateexplode("geom_0", F.lit(7)))\
  .drop("geom_0")\
  .write\
  .mode("overwrite")\
  .saveAsTable("nhda_area")

# COMMAND ----------

nhda_line = spark.read\
  .format("ogr")\
  .option("vsizip", "false")\
  .load("dbfs:/geospatial/hazard_risk/hydrography/data/Shape/NHDLine.shp")\
  .repartition(200, F.rand()) # ensure data is reshuffled, this is important for geospatial data after reading

nhda_line.display()

# COMMAND ----------

# MAGIC %%mosaic_kepler
# MAGIC nhda_line "geom_0" "geometry"

# COMMAND ----------

nhda_line\
  .withColumn("cell_id", mos.grid_tessellateexplode("geom_0", F.lit(7)))\
  .drop("geom_0")\
  .write\
  .mode("overwrite")\
  .saveAsTable("nhda_line")

# COMMAND ----------


